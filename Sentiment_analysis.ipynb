{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPp+TD0pm9nO9mMpAQaeo2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atomicamit24/Minor-Projects-using-AIML/blob/main/Sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "print(\"Loading the dataset...\")\n",
        "# Assuming the user has uploaded the 'IMDB Dataset' file\n",
        "url_csv = '/content/IMDB Dataset.csv' # Updated filename to match uploaded file\n",
        "df = pd.read_csv(url_csv)\n",
        "\n",
        "print(\"Dataset loaded successfully! Here's a preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# --- 2. Prepare the Data ---\n",
        "# Convert sentiment labels from text ('positive'/'negative') to numbers (1/0)\n",
        "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "# Separate the reviews (features, X) from the sentiments (labels, y)\n",
        "X = df['review']\n",
        "y = df['sentiment']\n",
        "\n",
        "# Split the data into a training set (80%) and a testing set (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"\\nData split into {len(X_train)} training samples and {len(X_test)} testing samples.\")\n",
        "\n",
        "# --- 3. Feature Extraction (Text to Numbers) ---\n",
        "# Create and configure the TF-IDF Vectorizer\n",
        "# This will convert text into numerical vectors, ignoring common English stop words\n",
        "# and focusing on the top 5000 most frequent words.\n",
        "print(\"Converting text to numbers using TF-IDF...\")\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "\n",
        "# Learn the vocabulary from the training data and transform it into vectors\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same learned vocabulary\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "print(\"Text converted successfully!\")\n",
        "\n",
        "# --- 4. Train the Machine Learning Model ---\n",
        "# Create the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n",
        "\n",
        "# Train the model on the training data\n",
        "print(\"\\nTraining the model...\")\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "print(\"Model training complete!\")\n",
        "\n",
        "# --- 5. Evaluate the Model ---\n",
        "# Make predictions on the unseen test data\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Show a detailed report of the model's performance\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n",
        "\n",
        "# --- 6. Test with a New Review ---\n",
        "print(\"--- Testing with a new review ---\")\n",
        "# Get input from the user\n",
        "my_review = input(\"Please enter the movie review you want to analyze: \")\n",
        "\n",
        "# Convert the new review into a numerical vector using the same vectorizer\n",
        "my_review_tfidf = vectorizer.transform([my_review])\n",
        "\n",
        "# Use the trained model to predict the sentiment\n",
        "prediction = model.predict(my_review_tfidf)\n",
        "\n",
        "# Print the final result\n",
        "if prediction[0] == 1:\n",
        "    print(\"\\nPrediction for your review: POSITIVE üëç\")\n",
        "else:\n",
        "    print(\"\\nPrediction for your review: NEGATIVE üëé\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu66FiEcuwBc",
        "outputId": "bfb950fa-6018-4b8c-d909-c83453ba98fb",
        "collapsed": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset...\n",
            "Dataset loaded successfully! Here's a preview:\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "\n",
            "Data split into 40000 training samples and 10000 testing samples.\n",
            "Converting text to numbers using TF-IDF...\n",
            "Text converted successfully!\n",
            "\n",
            "Training the model...\n",
            "Model training complete!\n",
            "\n",
            "Making predictions on the test set...\n",
            "Accuracy: 88.98%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.90      0.88      0.89      5000\n",
            "    Positive       0.88      0.90      0.89      5000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "--- Testing with a new review ---\n",
            "Please enter the movie review you want to analyze: 3 idiots\n",
            "\n",
            "Prediction for your review: NEGATIVE üëé\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ace8973a",
        "outputId": "673d9fdf-9ee7-4bad-815b-76607412165a"
      },
      "source": [
        "# Download the dataset\n",
        "!wget -O /content/imdb_dataset.csv https://raw.githubusercontent.com/AnkitMadaan/imdb_dataset/main/imdb_dataset.csv\n",
        "\n",
        "print(\"Download complete. The file should now be in the /content/ directory.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-30 10:12:24--  https://raw.githubusercontent.com/AnkitMadaan/imdb_dataset/main/imdb_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-30 10:12:25 ERROR 404: Not Found.\n",
            "\n",
            "Download complete. The file should now be in the /content/ directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h1sLiyxGyxv6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a65df95e",
        "outputId": "c703daa4-1a55-4d5c-8450-6028b14eacec"
      },
      "source": [
        "import os\n",
        "\n",
        "# List files in the /content/ directory\n",
        "files_in_content = os.listdir('/content/')\n",
        "print(\"Files in /content/ directory:\")\n",
        "for file in files_in_content:\n",
        "    print(file)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in /content/ directory:\n",
            ".config\n",
            "imdb_dataset.csv\n",
            "IMDB Dataset.csv\n",
            ".ipynb_checkpoints\n",
            "sample_data\n"
          ]
        }
      ]
    }
  ]
}